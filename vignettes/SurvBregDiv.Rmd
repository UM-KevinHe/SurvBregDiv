---
title: "SurvBregDiv: Transfer Learning for Time-to-Event Modelling via Bregman Divergence"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{survkl: Transfer-Learning Based Integrated Cox Models}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  markdown:
    wrap: sentence
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.alt = "Plot generated in survkl vignette")
library(SurvBregDiv)

library(dplyr)
library(kableExtra)
```


## Introduction

Accurate prognostic modeling is a central goal in survival analysis.
The rapid expansion of large-scale biobank initiatives—with rich genetic, molecular, imaging, and electronic health record data—has created new opportunities to improve predictive performance in clinical and epidemiologic research. However, these datasets often exhibit limited effective sample sizes, high dimensionality, low signal-to-noise ratios, and additional practical constraints including privacy considerations and restricted data access.

Integrating external information offers a principled strategy for improving model efficiency. Yet, classical data-integration methods typically rely on the assumption that multiple datasets arise from a common data-generating mechanism. In modern biomedical applications, this assumption is rarely satisfied. Misspecification due to population heterogeneity can induce substantial bias, motivating the development of transfer-learning approaches that explicitly accommodate between-source discrepancies.

While Bregman divergence has been successfully applied to borrowing information in binary-outcome settings, extending such ideas to censored time-to-event outcomes is nontrivial due to right censoring and the limited nature of available external survival information (e.g., predicted risk scores, fitted regression coefficients, or hazard ratios without access to a baseline hazard).

Beyond full-cohort survival studies, many biomedical investigations rely on the nested case–control (NCC) design to alleviate the burden of labor-intensive measurements, high-cost data acquisition, and destructive or finite biospecimen assays. Under an NCC design, only a small number of matched controls are sampled at each failure time, producing survival data that are analyzed through conditional logistic regression applied to matched risk sets. Despite its practical relevance, no existing methodology or software supports transfer learning or external information borrowing under NCC designs.

The `SurvBregDiv` package addresses these challenges by providing a unified transfer-learning framework for both full-cohort Cox data and nested case–control designs. The methods integrate external information in a privacy-preserving manner and are applicable to both low-dimensional settings and high-dimensional variable selection with ridge, lasso, and elastic net penalties.


### Key Features

- **Transfer learning via KL/Bregman shrinkage**  
  Integrates external information through Bregman divergence–based penalization, enabling adaptive borrowing from heterogeneous data sources.

- **Privacy-preserving external information use**  
  Operates on summary-level external inputs—such as fitted coefficients or risk scores—without requiring individual-level external data access.

- **Heterogeneity-aware borrowing**  
  Accommodates population differences through tuning-parameter–controlled shrinkage, selectively borrowing strength only when sources are compatible.

- **High-dimensional modeling with regularization**  
  Supports penalized KL-integrated models, including ridge, lasso, and elastic net penalties for variable selection and shrinkage.

- **Flexible external information formats**  
  Allows external inputs in the form of coefficients, risk scores, or partially overlapping covariate sets.

- **Built-in cross-validation for tuning**  
  Provides cross-validation criteria tailored for survival outcomes, including C-index, predicted deviance, and V&VH loss.

This vignette introduces the core functionalities of `SurvBregDiv` and illustrates workflows for both low- and high-dimensional applications.



## Installation

You can install from CRAN:

```{r, eval=FALSE}
install.packages("SurvBregDiv")
```

Or install the development version of `SurvBregDiv` from GitHub:

```{r, eval=FALSE}
require(devtools)
require(remotes)
remotes::install_github("UM-KevinHe/SurvBregDiv", ref = "main")
```


## Quick Start

This section provides a brief overview of the main functions using example datasets included in the package.

First, load the package:

```{r}
library(SurvBregDiv)
```

### Full-Cohort Cox Model with Bregman Divergence Integration

#### Low-Dimensional Integration

The low-dimensional Bregman-divergence–integrated Cox model is intended for settings where the number of predictors is modest. External information—either in the form of external Cox coefficients (`beta`) or pre-computed external risk scores (`RS`)—is incorporated through a Bregman-divergence penalization mechanism.

The tuning parameter `eta` controls the strength of information borrowing:

- `eta = 0` reduces to the standard Cox model (no external borrowing), and  
- larger values of `eta` increasingly shrink the fitted coefficients toward the external information.

Two specific divergence choices are supported:

- **Kullback–Leibler (KL) divergence**, implemented via `coxkl()`, and  
- **squared Mahalanobis distance**, implemented via `cox_MDTL()`.

For both formulations, the optimal `eta` can be selected through cross-validation using `cv.coxkl()` or `cv.cox_MDTL()`, respectively.

We illustrate the workflow using the built-in low-dimensional simulated dataset `ExampleData_lowdim`, which consists of a training set (100 samples) and a test set (2000 samples) with 6 predictors. We first extract the training components:

```{r}
data(ExampleData_lowdim)

train  <- ExampleData_lowdim$train
test   <- ExampleData_lowdim$test

z      <- train$z
delta  <- train$status
time   <- train$time
strat  <- train$stratum
```

and externally derived coefficients beta_external:
```{r}
beta_ext <- ExampleData_lowdim$beta_external_fair
```

We generate a sequence of tuning parameter `eta` values via the internal utility `generate_eta()` and fit the integrated model across this grid:
```{r}
eta_list <- generate_eta(method = "exponential", n = 50, max_eta = 10)
```

##### Model Fitting:

For the KL divergence–based integrated model, we use the function `coxkl()`:

```{r}
coxkl_est <- coxkl(
  z = z,
  delta = delta,
  time = time,
  stratum = strat,
  beta = beta_ext,
  etas = eta_list
)
```

For the squared Mahalanobis distance–based integrated model, we use `cox_MDTL()`:

```{r}
cox_MDTL_est <- cox_MDTL(
  z = z,
  delta = delta,
  time = time,
  stratum = strat,
  beta = beta_ext,
  vcov = NULL,
  etas = eta_list
)
```

Note that the squared Mahalanobis distance formulation requires a user-specified weighting matrix \eqn{Q} via the argument `vcov`. In standard Mahalanobis distance settings, \eqn{Q} is taken to be the inverse covariance matrix of the coefficients. If `vcov = NULL`, the function defaults to the identity matrix.


Users may instead supply an external risk score vector:

```{r}
RS_ext <- as.matrix(z) %*% as.matrix(beta_ext)

coxkl_est.RS <- coxkl(
  z = z,
  delta = delta,
  time = time,
  stratum = strat,
  RS = RS_ext,
  etas = eta_list
)
```

For datasets containing tied event times, users may apply the `coxkl_ties()` function, which extends integrated Cox model to handle ties. The following example illustrates the use of the Breslow method for tie handling:


```{r}
time_ties <- round(time, 2)   # Rounding time introduces ties for demonstration

coxkl_ties_est <- coxkl_ties(
  z = z,
  delta = delta,
  time = time_ties,
  stratum = strat,
  beta = beta_ext,
  etas = eta_list,
  ties = "breslow"
)
```


##### Hyperparameter Tuning via Cross-Validation:

The function `cv.coxkl` and `cv.cox_MDTL` performs K-fold (default 5) cross-validation to choose the integration parameter.
It supports four criteria:

- `"V&VH"` — V&VH loss  
- `"LinPred"` — predicted partial deviance  
- `"CIndex_pooled"` — pooled comparable pairs  
- `"CIndex_foldaverage"` — per-fold stratified C-index  

Below is an example using the default `"V&VH"` criterion:

```{r}
cv.coxkl_est <- cv.coxkl(
  z = z,
  delta = delta,
  time = time,
  stratum = strat,
  beta = beta_ext,
  etas = eta_list,
  nfolds = 5,
  criteria = "V&VH",
  seed = 1)
```



##### Model Visualization:

Objects of model fittings (i.e. from either `coxkl` or `cox_MDTL`) from can be visualized using the S3 plotting method `plot()`.  
This function displays how model performance changes across the `eta`–sequence used during fitting.

Two types of performance criteria are supported:

- `"loss"`  
  (default; −2 × partial log-likelihood, normalized by sample size)

- `"CIndex"`  
  (stratified concordance index)
  
Users may directly call the `plot()` method to visualize the model's fitted performance on the training data without providing additional test data. If a test set is supplied, performance metrics are computed using the test set instead:

```{r}
plot(
  cox_MDTL_est,
  test_z       = test$z,
  test_time    = test$time,
  test_delta   = test$status,
  test_stratum = test$stratum,
  criteria     = "loss"
) 
```


The cross-validated performance curve from hyperparameter tuning functions `cv.coxkl` or `cv.cox_MDTL` can be visualized directly using `cv.plot()`:

```{r}
cv.plot(cv.coxkl_est)
```

- The solid purple curve displays the cross-validated loss across different values of `eta`.
- The green dotted horizontal line marks the internal baseline at `eta` = 0, representing the model that does not incorporate external information.
- The vertical dashed orange line indicates the optimal `eta` value, where the cross-validated loss is minimized.

A comparison between the purple curve and the green baseline shows whether borrowing external information improves prediction performance.
Whenever the purple curve falls below the green line, using external information (`eta` > 0) yields better predictive accuracy than relying solely on the internal model.









### Nested Case-Control Design with Bregman Divergence Integration

