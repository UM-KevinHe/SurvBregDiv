% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cox_MDTL_enet.R
\name{cox_MDTL_enet}
\alias{cox_MDTL_enet}
\title{Fit Cox Model with Multi-Domain Transfer Learning and Elastic Net Penalty}
\usage{
cox_MDTL_enet(
  z,
  delta,
  time,
  stratum = NULL,
  beta,
  vcov = NULL,
  eta = NULL,
  alpha = NULL,
  lambda = NULL,
  nlambda = 100,
  lambda.min.ratio = ifelse(n < p, 0.05, 0.001),
  lambda.early.stop = FALSE,
  tol = 1e-04,
  Mstop = 1000,
  max.total.iter = (Mstop * nlambda),
  group = 1:ncol(z),
  group.multiplier = NULL,
  standardize = T,
  nvar.max = ncol(z),
  group.max = length(unique(group)),
  stop.loss.ratio = 0.01,
  actSet = TRUE,
  actIter = Mstop,
  actGroupNum = sum(unique(group) != 0),
  actSetRemove = F,
  returnX = FALSE,
  trace.lambda = FALSE,
  message = FALSE,
  data_sorted = FALSE,
  ...
)
}
\arguments{
\item{z}{Matrix of predictors (n x p).}

\item{delta}{Vector of event indicators (1 for event, 0 for censored).}

\item{time}{Vector of observed survival times.}

\item{stratum}{Vector indicating the stratum membership. If NULL, all observations are assumed to be in the same stratum.}

\item{beta}{Vector of external coefficients (length p). This represents the prior knowledge or "source" model coefficients.}

\item{vcov}{Optional weighting matrix (p x p) for the external information. Typically the inverse covariance matrix (precision matrix) of the external estimator. If NULL, defaults to the identity matrix.}

\item{eta}{Scalar. The transfer learning parameter (>= 0). Controls the strength of the external information. \code{eta = 0} ignores external info.}

\item{alpha}{The Elastic Net mixing parameter, with \eqn{0 \le \alpha \le 1}. \code{alpha=1} is the lasso penalty, and \code{alpha=0} the ridge penalty.}

\item{lambda}{Optional user-supplied lambda sequence. If NULL, the algorithm generates its own sequence.}

\item{nlambda}{The number of lambda values. Default is 100.}

\item{lambda.min.ratio}{Smallest value for lambda, as a fraction of lambda.max. Default depends on sample size relative to features.}

\item{lambda.early.stop}{Logical. Whether to stop early if the deviance changes minimally.}

\item{tol}{Convergence threshold for coordinate descent.}

\item{Mstop}{Maximum number of iterations per lambda step.}

\item{max.total.iter}{Maximum total iterations across all lambda values.}

\item{group}{Vector describing the grouping of the coefficients. Default is \code{1:ncol(z)} (no grouping).}

\item{group.multiplier}{Vector of multipliers for each group size.}

\item{standardize}{Logical. Should the predictors be standardized before fitting? Default is TRUE.}

\item{nvar.max}{Maximum number of variables allowed in the model.}

\item{group.max}{Maximum number of groups allowed in the model.}

\item{stop.loss.ratio}{Ratio of loss change to stop the path early.}

\item{actSet}{Logical. Whether to use active set convergence strategy.}

\item{actIter}{Number of iterations for active set.}

\item{actGroupNum}{Number of active groups.}

\item{actSetRemove}{Logical. Whether to remove inactive groups from the active set.}

\item{returnX}{Logical. If TRUE, returns the standardized design matrix and other data details.}

\item{trace.lambda}{Logical. If TRUE, prints the current lambda during fitting.}

\item{message}{Logical. If TRUE, prints warnings and progress messages.}

\item{data_sorted}{Logical. Internal flag indicating if data is already sorted by time/stratum.}

\item{...}{Additional arguments.}
}
\value{
An object of class \code{"cox_MDTL_enet"} containing:
\itemize{
\item \code{beta}: Matrix of estimated coefficients (p x nlambda).
\item \code{lambda}: The sequence of lambda values used.
\item \code{likelihood}: Vector of negative partial log-likelihood values.
\item \code{df}: Degrees of freedom for each lambda.
\item \code{W}: Matrix of exponential linear predictors.
\item \code{iter}: Number of iterations for each lambda.
\item \code{data}: List of input data.
}
}
\description{
Fits a Cox Proportional Hazards model that integrates external information (Transfer Learning)
using an Elastic Net regularization path. The method incorporates prior knowledge from
external coefficients (\code{beta}) and an optional weight matrix (\code{vcov}), controlled
by the transfer learning parameter \code{eta}.

The objective function minimizes the negative partial likelihood plus a transfer learning
penalty term \eqn{\eta (\beta - \beta_{ext})^T Q (\beta - \beta_{ext})} and the
Elastic Net penalty.
}
\examples{
\donttest{
data(ExampleData_highdim)
train_dat_highdim <- ExampleData_highdim$train
beta_external_highdim <- ExampleData_highdim$beta_external

cox_MDTL_enet_est <- cox_MDTL_enet(
  z = train_dat_highdim$z,
  delta = train_dat_highdim$status,
  time = train_dat_highdim$time,
  stratum = train_dat_highdim$stratum,
  beta = beta_external_highdim,
  vcov = NULL,
  eta = 0,
  alpha = 1
)
}
}
